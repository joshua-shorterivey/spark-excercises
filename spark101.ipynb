{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Using the [repo setup directions](https://ds.codeup.com/fundamentals/git/), setup a new local and remote repository named `spark-exercises`. The local version of your repo should live inside of `~/codeup-data-science`. This repo should be named `spark-exercises`\n",
    "\n",
    "Save this work in your `spark-exercises` repo. Then add, commit, and push your changes.\n",
    "\n",
    "Create a jupyter notebook or python script named `spark101` for this exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/20 14:49:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/20 14:49:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "#create spark session builder\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "    - The name of the column should be `language`\n",
    "    - View the schema of the dataframe\n",
    "    - Output the shape of the dataframe\n",
    "    - Show the first 5 records in the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[language: string, projects: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "fav_language = spark.createDataFrame([\n",
    "    Row(language='python', projects=5),\n",
    "    Row(language='swift', projects=2),\n",
    "    Row(language='javascript', projects=1),\n",
    "    Row(language='basic', projects=1),\n",
    "    Row(language='r', projects=0),\n",
    "    Row(language='c++', projects=0)\n",
    "    ])\n",
    "fav_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      " |-- projects: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#view schema of data frame\n",
    "fav_language.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 rows 2 columns\n"
     ]
    }
   ],
   "source": [
    "#output shape of dataframe\n",
    "#count gives number of rows, , len of df.columns gives number of columns\n",
    "print(fav_language.count(), 'rows', len(fav_language.columns), 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|  language|projects|\n",
      "+----------+--------+\n",
      "|    python|       5|\n",
      "|     swift|       2|\n",
      "|javascript|       1|\n",
      "|     basic|       1|\n",
      "|         r|       0|\n",
      "+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show the first 5 records in the data frame\n",
    "fav_language.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the `mpg` dataset as a spark dataframe.\n",
    "\n",
    "    * Create 1 column of output that contains a message like the one below for each vehicle:\n",
    "\n",
    "            The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "    * Transform the `trans` column so that it only contains either `manual` or `auto`.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "\n",
    "#import functions to use concat, sum, avg, min, max, ocount,  mean,  concat, and lit, regexpt_extract, regexp_replace\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "mpg = spark.createDataFrame(data('mpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 1 column of output that contains a message for each vehicle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------+\n",
      "|concat(The , year, manufacturer, model,  has a , cyl,  cylinder engine.)|\n",
      "+------------------------------------------------------------------------+\n",
      "|The 1999audia4 has a 4 cylinder engine.                                 |\n",
      "|The 1999audia4 has a 4 cylinder engine.                                 |\n",
      "|The 2008audia4 has a 4 cylinder engine.                                 |\n",
      "|The 2008audia4 has a 4 cylinder engine.                                 |\n",
      "|The 1999audia4 has a 6 cylinder engine.                                 |\n",
      "+------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(mpg.select(F.concat(F.lit('The '), mpg.year, mpg.manufacturer, mpg.model, F.lit(' has a '), mpg.cyl, F.lit(' cylinder engine.') ))).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the `trans` column so that it only contains either `manual` or `auto`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     trans|\n",
      "+----------+\n",
      "|  auto(l5)|\n",
      "|manual(m5)|\n",
      "|manual(m6)|\n",
      "+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select('trans').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------------------------------------+\n",
      "|     trans|CASE WHEN contains(trans, auto) THEN auto ELSE manual END|\n",
      "+----------+---------------------------------------------------------+\n",
      "|  auto(l5)|                                                     auto|\n",
      "|manual(m5)|                                                   manual|\n",
      "|manual(m6)|                                                   manual|\n",
      "|  auto(av)|                                                     auto|\n",
      "|  auto(l5)|                                                     auto|\n",
      "|manual(m5)|                                                   manual|\n",
      "|  auto(av)|                                                     auto|\n",
      "|manual(m5)|                                                   manual|\n",
      "|  auto(l5)|                                                     auto|\n",
      "|manual(m6)|                                                   manual|\n",
      "|  auto(s6)|                                                     auto|\n",
      "|  auto(l5)|                                                     auto|\n",
      "|manual(m5)|                                                   manual|\n",
      "|  auto(s6)|                                                     auto|\n",
      "|manual(m6)|                                                   manual|\n",
      "|  auto(l5)|                                                     auto|\n",
      "|  auto(s6)|                                                     auto|\n",
      "|  auto(s6)|                                                     auto|\n",
      "|  auto(l4)|                                                     auto|\n",
      "|  auto(l4)|                                                     auto|\n",
      "+----------+---------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select('trans',\n",
    "    F.when(mpg.trans.contains('auto'), 'auto')\n",
    "    .otherwise('manual')).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|     trans|attempts|\n",
      "+----------+--------+\n",
      "|  auto(l5)|    auto|\n",
      "|manual(m5)|  manual|\n",
      "|manual(m6)|  manual|\n",
      "+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select('trans', F.regexp_extract('trans', r'^(\\w+)', 1).alias('attempts')).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the `tips` dataset as a spark dataframe.\n",
    "\n",
    "    1. What percentage of observations are smokers?\n",
    "    1. Create a column that contains the tip percentage\n",
    "    1. Calculate the average tip percentage for each combination of sex and smoker.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = spark.createDataFrame(data('tips'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- tip: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#similar to df.info\n",
    "tips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38114754098360654"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tips.rollup(tips.smoker== 'Yes').count().show()\n",
    "#tips.groupBy(tips.smoker).agg(F.sum(tips.smoker == 'Yes')).show() --> not good\n",
    "tips.filter(tips.smoker == 'Yes').count()/tips.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a column that contains the tip percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- tip: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------------+\n",
      "|total_bill| tip|tip_percentage|\n",
      "+----------+----+--------------+\n",
      "|     16.99|1.01|          0.06|\n",
      "|     10.34|1.66|          0.16|\n",
      "|     21.01| 3.5|          0.17|\n",
      "|     23.68|3.31|          0.14|\n",
      "|     24.59|3.61|          0.15|\n",
      "+----------+----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col1 = F.round((tips.tip/tips.total_bill),2).alias('tip_percentage')\n",
    "tips.select(tips.total_bill, tips.tip, col1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "    - Convert the temperatures to fahrenheit.\n",
    "    - Which month has the most rain, on average?\n",
    "    - Which year was the windiest?\n",
    "    - What is the most frequent type of weather in January?\n",
    "    - What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "    - What percentage of days were rainy in q3 of 2015?\n",
    "    - For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
